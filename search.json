[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Damien Dotta. Maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":") c (2022). parquetize: Functions convert files parquet format. R package version 0.2.0.","code":"@Manual{,   title = {parquetize: Functions to convert files to parquet format},   author = {c )},   year = {2022},   note = {R package version 0.2.0}, }"},{"path":"/index.html","id":"package-package-parquetize-","dir":"","previous_headings":"","what":"Functions to convert files to parquet format","title":"Functions to convert files to parquet format","text":"R package allows convert databases different formats (csv, SAS, SPSS, Stata, rds, JSON, ndJSON) parquet format function.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Functions to convert files to parquet format","text":"","code":"remotes::install_github(\"ddotta/parquetize\") library(parquetize) install.packages(\"parquetize\",                   repos = \"https://nexus.insee.fr/repository/r-local\",                   type = \"source\")"},{"path":"/index.html","id":"why-this-package-","dir":"","previous_headings":"","what":"Why this package ?","title":"Functions to convert files to parquet format","text":"package simple wrapper useful functions haven, readr, jsonlite arrow packages. working, realized often repeating operation working parquet files : import file R {haven}, {jsonlite} {readr}. export file parquet format fervent DRY principle (don’t repeat ) 3 exported functions package make life easier execute operations within function : benefit function allows convert csv files whether stored locally available internet directly csv format inside zip. benefit function handles JSON ndJSON files function. one function use 2 cases. rds_to_parquet() benefit functionis handles SAS, SPSS Stata files function. one function use 3 cases. last benefit using package {parquetize} functions allow create single parquet files partitioned files depending arguments chosen functions. details, see documentation examples : - csv_to_parquet(). - json_to_parquet(). - rds_to_parquet(). - table_to_parquet().","code":""},{"path":"/index.html","id":"contribution","dir":"","previous_headings":"","what":"Contribution","title":"Functions to convert files to parquet format","text":"Feel welcome contribute add features find useful daily work. Ideas welcomed issues.","code":""},{"path":"/reference/csv_to_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a csv file to parquet format — csv_to_parquet","title":"Convert a csv file to parquet format — csv_to_parquet","text":"function allows convert csv file parquet format.","code":""},{"path":"/reference/csv_to_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a csv file to parquet format — csv_to_parquet","text":"","code":"csv_to_parquet(   path_to_csv,   url_to_csv,   csv_as_a_zip = FALSE,   filename_in_zip,   path_to_parquet,   compression = \"snappy\",   compression_level = NULL,   partition = \"no\",   encoding = \"UTF-8\",   progressbar = \"yes\",   ... )"},{"path":"/reference/csv_to_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a csv file to parquet format — csv_to_parquet","text":"path_to_csv string indicates path csv file url_to_csv string indicates URL csv file csv_as_a_zip boolean indicates csv stored zip filename_in_zip name csv file zip (useful several csv included zip). Required `csv_as_a_zip` TRUE. path_to_parquet string indicates path directory parquet file stored compression compression algorithm. Default \"snappy\". compression_level compression level. Meaning depends compression algorithm. partition string (\"yes\" \"\" - default) indicates whether want create partitioned parquet file. \"yes\", `\"partitioning\"` argument must filled . case, folder created modality variable filled `\"partitioning\"`. encoding string indicates character encoding input file. progressbar string () (\"yes\" \"\" - default) indicates whether want progress bar display ... additional format-specific arguments, see arrow::write_parquet() arrow::write_dataset() informations.","code":""},{"path":"/reference/csv_to_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a csv file to parquet format — csv_to_parquet","text":"parquet file, invisibly","code":""},{"path":"/reference/csv_to_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert a csv file to parquet format — csv_to_parquet","text":"Several conversion possibilities offered : locally stored file. Argument `path_to_csv` must used; URL. Argument `url_to_csv` must used. Two conversions possibilities offered : Convert single parquet file. Argument `path_to_parquet` must used; Convert partitioned parquet file. Additionnal arguments `partition` `partitioning` must used;","code":""},{"path":"/reference/csv_to_parquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a csv file to parquet format — csv_to_parquet","text":"","code":"# Conversion from a local csv file to a single parquet file :  csv_to_parquet(   path_to_csv = parquetize_example(\"region_2022.csv\"),   path_to_parquet = tempdir(),   progressbar = \"no\" ) #>  #> The csv file is available in parquet format under /tmp/RtmpOijpMb  # Conversion from a local csv file  to a partitioned parquet file  :  csv_to_parquet(   path_to_csv = parquetize_example(\"region_2022.csv\"),   path_to_parquet = tempdir(),   progressbar = \"no\",   partition = \"yes\",   partitioning =  c(\"REG\") ) #>  #> The csv file is available in parquet format under /tmp/RtmpOijpMb  # Conversion from a URL and a csv file with \"gzip\" compression :  csv_to_parquet(   url_to_csv = \"https://stats.govt.nz/assets/Uploads/Research-and-development-survey/Research-and-development-survey-2021/Download-data/research-and-development-survey-2021-csv.csv\",   path_to_parquet = tempdir(),   compression = \"gzip\",   compression_level = 5,   progressbar = \"no\" ) #>  #> The csv file is available in parquet format under /tmp/RtmpOijpMb  # Conversion from a URL and a zipped file :  csv_to_parquet(   url_to_csv = \"https://www.insee.fr/fr/statistiques/fichier/5057840/cog_ensemble_2021_csv.zip\",   csv_as_a_zip = TRUE,   filename_in_zip = \"commune2021.csv\",   path_to_parquet = tempdir(),   progressbar = \"no\" ) #>  #> The csv file is available in parquet format under /tmp/RtmpOijpMb"},{"path":"/reference/json_to_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a json file to parquet format — json_to_parquet","title":"Convert a json file to parquet format — json_to_parquet","text":"function allows convert json ndjson file parquet format.","code":""},{"path":"/reference/json_to_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a json file to parquet format — json_to_parquet","text":"","code":"json_to_parquet(   path_to_json,   path_to_parquet,   format = \"json\",   partition = \"no\",   progressbar = \"yes\",   ... )"},{"path":"/reference/json_to_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a json file to parquet format — json_to_parquet","text":"path_to_json string indicates path csv file path_to_parquet string indicates path directory parquet file stored format string indicates format \"json\" (default) \"ndjson\" partition string (\"yes\" \"\" - default) indicates whether want create partitioned parquet file. \"yes\", `\"partitioning\"` argument must filled . case, folder created modality variable filled `\"partitioning\"`. progressbar string () (\"yes\" \"\" - default) indicates whether want progress bar display ... additional format-specific arguments, see arrow::write_parquet() arrow::write_dataset() informations.","code":""},{"path":"/reference/json_to_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a json file to parquet format — json_to_parquet","text":"parquet file, invisibly","code":""},{"path":"/reference/json_to_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert a json file to parquet format — json_to_parquet","text":"Two conversions possibilities offered : Convert single parquet file. Argument `path_to_parquet` must used; Convert partitioned parquet file. Additionnal arguments `partition` `partitioning` must used;","code":""},{"path":"/reference/json_to_parquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a json file to parquet format — json_to_parquet","text":"","code":"# Conversion from a local json file to a single parquet file ::  json_to_parquet(   path_to_json = system.file(\"extdata\",\"iris.json\",package = \"parquetize\"),   path_to_parquet = tempdir(),   progressbar = \"no\" ) #>  #> The json file is available in parquet format under /tmp/RtmpOijpMb  # Conversion from a local ndjson file to a partitioned parquet file  ::  json_to_parquet(   path_to_json = system.file(\"extdata\",\"iris.ndjson\",package = \"parquetize\"),   path_to_parquet = tempdir(),   format = \"ndjson\",   progressbar = \"no\" ) #>  #> The ndjson file is available in parquet format under /tmp/RtmpOijpMb"},{"path":"/reference/parquetize_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Get path to parquetize example — parquetize_example","title":"Get path to parquetize example — parquetize_example","text":"parquetize comes bundled number sample files `inst/extdata` directory. function make easy access","code":""},{"path":"/reference/parquetize_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get path to parquetize example — parquetize_example","text":"","code":"parquetize_example(file = NULL)"},{"path":"/reference/parquetize_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get path to parquetize example — parquetize_example","text":"file Name file. `NULL`, example files listed.","code":""},{"path":"/reference/parquetize_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get path to parquetize example — parquetize_example","text":"","code":"parquetize_example() #> [1] \"iris.json\"       \"iris.ndjson\"     \"iris.rds\"        \"region_2022.csv\" parquetize_example(\"region_2022.csv\") #> [1] \"/home/runner/work/_temp/Library/parquetize/extdata/region_2022.csv\""},{"path":"/reference/rds_to_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a rds file to parquet format — rds_to_parquet","title":"Convert a rds file to parquet format — rds_to_parquet","text":"function allows convert rds file parquet format.","code":""},{"path":"/reference/rds_to_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a rds file to parquet format — rds_to_parquet","text":"","code":"rds_to_parquet(   path_to_rds,   path_to_parquet,   partition = \"no\",   progressbar = \"yes\",   ... )"},{"path":"/reference/rds_to_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a rds file to parquet format — rds_to_parquet","text":"path_to_rds string indicates path csv file path_to_parquet string indicates path directory parquet file stored partition string (\"yes\" \"\" - default) indicates whether want create partitioned parquet file. \"yes\", `\"partitioning\"` argument must filled . case, folder created modality variable filled `\"partitioning\"`. progressbar string () (\"yes\" \"\" - default) indicates whether want progress bar display ... additional format-specific arguments, see arrow::write_parquet() arrow::write_dataset() informations.","code":""},{"path":"/reference/rds_to_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a rds file to parquet format — rds_to_parquet","text":"parquet file, invisibly","code":""},{"path":"/reference/rds_to_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert a rds file to parquet format — rds_to_parquet","text":"Two conversions possibilities offered : Convert single parquet file. Argument `path_to_parquet` must used; Convert partitioned parquet file. Additionnal arguments `partition` `partitioning` must used;","code":""},{"path":"/reference/rds_to_parquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a rds file to parquet format — rds_to_parquet","text":"","code":"# Conversion from a local rds file to a single parquet file ::  rds_to_parquet(   path_to_rds = system.file(\"extdata\",\"iris.rds\",package = \"parquetize\"),   path_to_parquet = tempdir(),   progressbar = \"no\" ) #>  #> The rds file is available in parquet format under /tmp/RtmpOijpMb  # Conversion from a local rds file to a partitioned parquet file  ::  rds_to_parquet(   path_to_rds = system.file(\"extdata\",\"iris.rds\",package = \"parquetize\"),   path_to_parquet = tempdir(),   progressbar = \"no\",   partition = \"yes\",   partitioning =  c(\"Species\") ) #>  #> The rds file is available in parquet format under /tmp/RtmpOijpMb"},{"path":"/reference/table_to_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an input file to parquet format — table_to_parquet","title":"Convert an input file to parquet format — table_to_parquet","text":"function allows convert input file parquet format.","code":""},{"path":"/reference/table_to_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an input file to parquet format — table_to_parquet","text":"","code":"table_to_parquet(   path_to_table,   path_to_parquet,   nb_rows = NULL,   partition = \"no\",   encoding = NULL,   progressbar = \"yes\",   ... )"},{"path":"/reference/table_to_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an input file to parquet format — table_to_parquet","text":"path_to_table string indicates path input file (forget extension). path_to_parquet string indicates path directory parquet files stored. nb_rows default NULL. Number rows process . number lines put R's RAM number lines written disk parquet file. partition string (\"yes\" \"\" - default) indicates whether want create partitioned parquet file. \"yes\", `\"partitioning\"` argument must filled . case, folder created modality variable filled `\"partitioning\"`. encoding string indicates character encoding input file. progressbar string () (\"yes\" \"\" - default) indicates whether want progress bar display ... additional format-specific arguments,  see arrow::write_parquet() arrow::write_dataset() informations.","code":""},{"path":"/reference/table_to_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an input file to parquet format — table_to_parquet","text":"Parquet files, invisibly","code":""},{"path":"/reference/table_to_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert an input file to parquet format — table_to_parquet","text":"handles SAS, SPSS Stata files function. one function use 3 cases. 3 cases, function guesses data format using extension input file (`path_to_table` argument). Two conversions possibilities offered : Convert single parquet file. Argument `path_to_parquet` must used; Convert partitioned parquet file. Additionnal arguments `partition` `partitioning` must used; avoid overcharging R's RAM, reading input files can done chunk. Argument  `nb_rows` must used.","code":""},{"path":"/reference/table_to_parquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert an input file to parquet format — table_to_parquet","text":"","code":"# Conversion from a SAS file to a single parquet file :  table_to_parquet(   path_to_table = system.file(\"examples\",\"iris.sas7bdat\", package = \"haven\"),   path_to_parquet = tempdir(),   progressbar = \"no\" ) #>  #> The SAS file is available in parquet format under /tmp/RtmpOijpMb  # Conversion from a SPSS file to a single parquet file :  table_to_parquet(   path_to_table = system.file(\"examples\",\"iris.sav\", package = \"haven\"),   path_to_parquet = tempdir(),   progressbar = \"no\" ) #>  #> The SPSS file is available in parquet format under /tmp/RtmpOijpMb # Conversion from a Stata file to a single parquet file without progress bar :  table_to_parquet(   path_to_table = system.file(\"examples\",\"iris.dta\", package = \"haven\"),   path_to_parquet = tempdir(),   progressbar = \"no\" ) #>  #> The Stata file is available in parquet format under /tmp/RtmpOijpMb  # Reading SAS file by chunk and with encoding and conversion from a SAS file to a single parquet file :  table_to_parquet(   path_to_table = system.file(\"examples\",\"iris.sas7bdat\", package = \"haven\"),   path_to_parquet = tempdir(),   nb_rows = 50,   encoding = \"utf-8\",   progressbar = \"no\" ) #>  #> The SAS file is available in parquet format under /tmp/RtmpOijpMb  # Conversion from a SAS file to a partitioned parquet file  :  table_to_parquet(   path_to_table = system.file(\"examples\",\"iris.sas7bdat\", package = \"haven\"),   path_to_parquet = tempdir(),   partition = \"yes\",   partitioning =  c(\"Species\"), # vector use as partition key   progressbar = \"no\" ) #>  #> The SAS file is available in parquet format under /tmp/RtmpOijpMb  # Reading SAS file by chunk and conversion from a SAS file to a partitioned parquet file :  table_to_parquet( path_to_table = system.file(\"examples\",\"iris.sas7bdat\", package = \"haven\"), path_to_parquet = tempdir(), nb_rows = 50, partition = \"yes\", partitioning =  c(\"Species\"), # vector use as partition key progressbar = \"no\" ) #>  #> The SAS file is available in parquet format under /tmp/RtmpOijpMb"},{"path":"/news/index.html","id":"parquetize-020","dir":"Changelog","previous_headings":"","what":"parquetize 0.2.0","title":"parquetize 0.2.0","text":"Added rds_to_parquet() function convert rds files parquet format. Added json_to_parquet() function convert json ndjson files parquet format. Added possibility convert csv file partitioned parquet file. Improving code coverage (#9) Check path_to_parquet exists functions csv_to_parquet() table_to_parquet() (@py-b)","code":""},{"path":"/news/index.html","id":"parquetize-010","dir":"Changelog","previous_headings":"","what":"parquetize 0.1.0","title":"parquetize 0.1.0","text":"Added table_to_parquet() function convert SAS, SPSS Stata files parquet format. Added csv_to_parquet() function convert csv files parquet format. Added parquetize_example() function get path package data examples. Added NEWS.md file track changes package.","code":""}]
