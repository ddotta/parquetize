% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/table_to_parquet.R
\name{table_to_parquet}
\alias{table_to_parquet}
\title{Convert an input file to parquet format}
\usage{
table_to_parquet(
  path_to_table,
  path_to_parquet,
  nb_rows = NULL,
  partition = "no",
  encoding = NULL,
  progressbar = "yes",
  ...
)
}
\arguments{
\item{path_to_table}{string that indicates the path to the input file (don't forget the extension).}

\item{path_to_parquet}{string that indicates the path to the directory where the parquet files will be stored.}

\item{nb_rows}{By default NULL. Number of rows to process at once. This is the number of lines put into R's RAM and the number of lines written to disk for the parquet file.}

\item{partition}{string ("yes" or "no" - by default) that indicates whether you want to create a partitioned parquet file.
If "yes", `"partitioning"` argument must be filled in. In this case, a folder will be created for each modality of the variable filled in `"partitioning"`.}

\item{encoding}{string that indicates the character encoding for the input file.}

\item{progressbar}{string () ("yes" or "no" - by default) that indicates whether you want a progress bar to display}

\item{...}{additional format-specific arguments, see [arrow::write_parquet()](https://arrow.apache.org/docs/r/reference/write_parquet.html) and [arrow::write_dataset()](https://arrow.apache.org/docs/r/reference/write_dataset.html) for more informations.}
}
\value{
Parquet files, invisibly
}
\description{
This function allows to convert an input file to parquet format. \cr
}
\details{
It handles SAS, SPSS and Stata files in a same function. There is only one function to use for these 3 cases.
For these 3 cases, the function guesses the data format using the extension of the input file (in the `path_to_table` argument). \cr

Two conversions possibilities are offered :

\itemize{

\item{Convert to a single parquet file. Argument `path_to_parquet` must then be used;}
\item{Convert to a partitioned parquet file. Additionnal arguments `partition` and `partitioning` must then be used;}

}

To avoid overcharging R's RAM, the reading of input files can be done by chunk. Argument  `nb_rows` must then be used.
}
\examples{
# Conversion from a SAS file to a single parquet file :

table_to_parquet(
  path_to_table = system.file("examples","iris.sas7bdat", package = "haven"),
  path_to_parquet = tempdir(),
  progressbar = "no"
)

# Conversion from a SPSS file to a single parquet file :

table_to_parquet(
  path_to_table = system.file("examples","iris.sav", package = "haven"),
  path_to_parquet = tempdir(),
  progressbar = "no"
)
# Conversion from a Stata file to a single parquet file without progress bar :

table_to_parquet(
  path_to_table = system.file("examples","iris.dta", package = "haven"),
  path_to_parquet = tempdir(),
  progressbar = "no"
)

# Reading SAS file by chunk and with encoding and conversion from a SAS file to a single parquet file :

table_to_parquet(
  path_to_table = system.file("examples","iris.sas7bdat", package = "haven"),
  path_to_parquet = tempdir(),
  nb_rows = 50,
  encoding = "utf-8",
  progressbar = "no"
)

# Conversion from a SAS file to a partitioned parquet file  :

table_to_parquet(
  path_to_table = system.file("examples","iris.sas7bdat", package = "haven"),
  path_to_parquet = tempdir(),
  partition = "yes",
  partitioning =  c("Species"), # vector use as partition key
  progressbar = "no"
)

# Reading SAS file by chunk and conversion from a SAS file to a partitioned parquet file :

table_to_parquet(
path_to_table = system.file("examples","iris.sas7bdat", package = "haven"),
path_to_parquet = tempdir(),
nb_rows = 50,
partition = "yes",
partitioning =  c("Species"), # vector use as partition key
progressbar = "no"
)
}
